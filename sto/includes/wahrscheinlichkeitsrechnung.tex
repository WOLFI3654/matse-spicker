\section{Wahrscheinlichkeitsrechnung}
\subsection{Einführung in die Kombinatorik}

\begin{bonus}{Urnenmodell}
    Ein \emph{Urnenmodell} ist ein Gedankenexperiment, das in der Wahrscheinlichkeitstheorie und in der Statistik verwendet wird, um verschiedene Zufallsexperimente auf einheitliche und anschauliche Weise zu modellieren.

    Dazu wird ein fiktives Gefäß, Urne genannt, mit einer bestimmten Anzahl an Kugeln gefüllt, die anschließend zufällig gezogen werden.
    Damit ist gemeint, dass bei jedem Zug alle in der Urne befindlichen Kugeln die gleiche Wahrscheinlichkeit haben, ausgewählt zu werden.
    Dadurch kann die Bestimmung interessierender Wahrscheinlichkeiten auf die Lösung kombinatorischer Abzählprobleme zurückgeführt werden.
\end{bonus}

\begin{defi}{Permutation}
    Eine Anordnung von $n$ verschiedenen Elementen in einer bestimmten Reihenfolge heißt eine \emph{Permutation} der $n$ Elemente.

    Für eine $n$-elementige Menge gilt für die Anzahl $P$ der Permutationen:
    \[
        P(n) = n \cdot (n-1) \cdot (n-1) \cdot \ldots \cdot 1 = n!
    \]

    Befinden sich unter den $n$ Elementen jeweils $n_1, n_2, \ldots, n_k$ gleiche, dann gilt:
    \[
        P(n ; n_1 ; n_2 ; \ldots, n_k) = \frac{n!}{n_1! \cdot n_2! \cdot \ldots \cdot n_k} \quad \text{mit} \ \sum_{i=1}^{k} n_i = n \quad k \leq n
    \]
\end{defi}

\begin{defi}{Kombination}
    Eine \emph{Kombination} oder ungeordnete Stichprobe ist in der Kombinatorik eine Auswahl von Objekten aus einer gegebenen Grundmenge, die (im Gegensatz zur Permutation) nicht alle Objekte der Grundmenge enthalten muss und bei der (im Gegensatz zur Permutation und Variation) die Reihenfolge unberücksichtigt bleibt.

    Darf jedes Objekt nur einmal auftreten, spricht man von einer \emph{Kombination ohne Wiederholung}.

    Um alle \emph{Kombinationen $k$-ter Ordnung ohne Wiederholung} zu erhalten, müssen alle Permutationen der $n$ Kugeln betrachtet werden, wobei ein Vertauschen der Kugeln auf Plätzen mit demselben Merkmal (wird gezogen $\to k$ bzw. wird nicht gezogen $\to n-k$) keine neue Kombination ergibt:
    \[
        C(n;k) = P(n;k;n-k) = \frac{n!}{k! \cdot (n-k)!} = \binom{n}{k}
    \]

    Können Objekte mehrfach ausgewählt werden, so spricht man von einer \emph{Kombination mit Wiederholung}.

    Um alle \emph{Kombinationen $k$-ter Ordnung mit Wiederholung} zu erhalten, gilt:
    \footnote{Zum Verständnis empfehle ich dieses Video: \href{https://youtu.be/ZcSSI6VY1kM}{COMBINATIONS with REPETITION - DISCRETE MATHEMATICS}}
    \[
        C_W(n;k) = P(n+k-1;k;n-1) = \frac{(n+k-1)!}{k! \cdot (n-1)!} = \binom{n+k-1}{k}
    \]
\end{defi}

\begin{defi}{Variation}
    Eine \emph{Variation} oder geordnete Stichprobe ist eine Auswahl von $k$ Objekten aus einer Menge von $n$ Objekten, wobei die Reihenfolge der Auswahl eine Rolle spielt.

    Bei einer \emph{Variation ohne Wiederholung} sollen $k$ Objekten (mit $k \leq n$) auf $k$ verfügbare Plätze platziert werden, wobei jedes Objekt nur höchstens einen Platz einnehmen darf.
    Es gibt für den ersten Platz $n$ mögliche Objekte, für den zweiten Platz $n - 1$ Objekte usw. bis zum $k$-ten Platz, für den es noch $n - k + 1$ mögliche Objekte gibt.
    Insgesamt gilt also:
    \[
        V(n;k) = k! \cdot C(n;k) = \frac{n!}{(n-k)!}
    \]

    Bei einer Variation mit Wiederholung werden aus $n$ Objekten $k$ Objekte unter Beachtung der Reihenfolge ausgewählt, wobei Objekte auch mehrfach ausgewählt werden können.
    Nachdem jedes der $n$ Objekte auf jedem der $k$ Plätze der Auswahl erscheinen kann, gilt demzufolge:
    \[
        V_W(n;k) = n^k
    \]
\end{defi}

\begin{bonus}{Kombinatoriktabelle}
    TO DO
\end{bonus}

\subsection{Grundbegriffe}

\begin{defi}{Zufallsexperiment}
    Damit ein Experiment ein \emph{Zufallsexperiment} ist, muss es folgende Eigenschaften aufweisen:
    \begin{itemize}
        \item Es gibt einen genau festgelegten Plan zur Durchführung.
        \item Alle möglichen Ergebnisse des Experiments sind vorab bekannt.
        \item Das Ergebnis jedes einzelnen Experiments kann nicht vorhergesagt werden (Zufälligkeit).
    \end{itemize}
    Ein Zufallsexperiment kann einmalig und unwiederholbar sein oder auch Serien von Durch- führungen mit gleichwertigen und von Durchführung zu Durchführung voneinander unabhängigen Versuchen ermöglichen.

    Weiter kann ein Zufallsexperiment \emph{einstufig} oder \emph{mehrstufig} sein.
\end{defi}

\begin{defi}{Ergebnismenge}
    Die Menge aller möglichen Ergebnisse eines Zufallsexperiments bezeichnen wir als \emph{Ergebnismenge} $\Omega$.
\end{defi}

\begin{defi}{Ereignis}
    Interessieren wir uns nicht für alle möglichen Ergebnisse des Zufallsexperiments, sondern nur für bestimmte, z.B. \enquote{Würfeln einer geraden Zahl}, so sprechen wir von einem \emph{Ereignis} $\omega$.

    \emph{Spezialfall}: Einelementige Teilmengen von $\Omega$ sind \emph{Elementarereignisse}
    \[
        \omega \subseteq \Omega \ \text{mit} \ \abs{\omega} = 1
    \]

    Ein Ereignis ist $A$ ist entweder:
    \begin{itemize}
        \item Das \emph{unmögliche} Ereignis ($A$ enthält kein Element von $\Omega$)
        \item Ein \emph{Elementarereignis} ($A$ enthält genau ein Element von $\Omega$)
        \item Eine \emph{Zusammenfassung} mehrerer Elementarereignisse ($A$ enthält mehrere Elemente von $\Omega$)
        \item Das \emph{sichere} Ereignis ($A$ enthält alle Elemente von $\Omega$ bzw. $A = \Omega$)
    \end{itemize}
\end{defi}

\begin{defi}{Ereignisraum}
    Die Menge aller Ereignisse, die sich aus der Ergebnismenge bilden lässt, heißt \emph{Ereignisraum}.
\end{defi}

\begin{bonus}{Zusammengesetzte Ereignisse}
    Da Ereignisse Teilmengen der Ergebnismenge sind, lassen sie sich auch wie Mengen verknüpfen.
    Wir erhalten dadurch zusammengesetzte Ereignisse:
    \begin{enumerate}
        \item \emph{Vereinigung}:
              \[
                  A \cup B = \{ \omega \mid \omega \in A \lor \omega \in B \}
              \]
        \item \emph{Durchschnitt} bzw. \emph{Schnittmenge}:
              \[
                  A \cap B = \{ \omega \mid \omega \in A \land \omega \in B \}
              \]
        \item \emph{Gegenereignis} bzw. \emph{Komplement}:
              \[
                  \conj{A} = \{ \omega \mid \omega \notin A \}
              \]
        \item \emph{Differenz}:
              \[
                  A \setminus B = \{ \omega \mid \omega \in A \land \omega \notin B \}
              \]
        \item \emph{Disjunkte Ereignisse}:
              \[
                  A \cap B = \emptyset \quad \iff \quad A \ \text{und} \ B \ \text{sind disjunkt}
              \]
    \end{enumerate}

    Analog zur Mengenalgebra gelten hier natürlich auch die Regeln von de Morgan\footnote{Siehe: \href{https://de.wikipedia.org/wiki/De-morgansche_Gesetze}{De-morgansche Gesetze}}.
\end{bonus}

\subsection{Wahrscheinlichkeit}

\begin{defi}{Laplace-Experiment}
    Es gibt eine Reihe von Zufallsexperimenten, bei denen keines der Elementarereignisse gegenüber einem anderen bevorzugt ist, d.h. bei ausreichend häufiger Wiederholung des Experimentes tritt jedes Elementarereignis mit nahezu gleicher Häufigkeit auf.
    Ein derartiges Experiment bezeichnen wir als \emph{Laplace-Experiment}.

    Einem Elementarereignis $\omega_i$ aus einer Ergebnismenge $\Omega$ mit $m$ möglichen Elementarereignissen wird definitionsgemäß die positive Zahl
    \[
        P(\{ \omega_i \}) = p(\omega_i) = \frac{1}{m} = \frac{1}{\abs{\Omega}}
    \]
    als \emph{Wahrscheinlichkeit} zugeordnet. Damit gilt für ein Ereignis $A$ direkt:
    \[
        P(A) = \sum_{\omega_i \in A} P(\{ \omega_i \}) = p(\omega_i) = \frac{\abs{A}}{m} = \frac{\abs{A}}{\abs{\Omega}}
    \]

    Das gilt allerdings nur, wenn:
    \begin{itemize}
        \item Die Ergebnismenge $\Omega$ endlich ist.
        \item Alle Elementarereignisse gleichwahrscheinlich sind.
    \end{itemize}
\end{defi}

\begin{defi}{Absolute Häufigkeit}
    Die \emph{absolute Häufigkeit} ist das Ergebnis einer einfachen Zählung von Objekten oder Ereignissen (besser Elementarereignissen).
    Sie gibt an, wie viele Elemente mit dem gleichen interessierenden Merkmal gezählt wurden.
\end{defi}

\begin{defi}{Relative Häufigkeit}
    Die \emph{relative Häufigkeit} gibt den Anteil der Elemente einer Menge wieder, bei denen eine bestimmte Merkmalsausprägung vorliegt.
    Sie wird berechnet, indem die absolute Häufigkeit eines Merkmals in einer zugrundeliegenden Menge durch die Anzahl der Objekte in dieser Menge geteilt wird.
    Die relative Häufigkeit ist also eine Bruchzahl und hat einen Wert zwischen 0 und 1.
\end{defi}

\begin{defi}{Wahrscheinlichkeitsaxiome}
    Seien $A, B, E$ Ereignisse.
    Es gilt allgemein:
    \begin{itemize}
        \item $P(\emptyset) = 0$
        \item $P(\conj{E}) = 1 - P(E)$
        \item $0 \leq P(E) \leq 1$
        \item $A \subseteq B \implies P(A) \leq P(B)$
        \item $P(A \cup B) = P(A) + P(B) - P(A \cap B) \leq P(A) + P(B)$
    \end{itemize}
\end{defi}

\begin{defi}{Ereignisalgebra}
    Es sei $\Omega$ eine nichtleere Menge.
    Eine Ereignisalgebra über $\Omega$ ist eine nichtleere Menge $S$ von Teilmengen von $\Omega$, für die gilt:
    \begin{itemize}
        \item Für jedes $E \in S$ ist $\conj{E} \in S$.
        \item Für jede Folge $E_1, E_2, \ldots \in S$ ist $\bigcup_{E_i \in \Omega} E_i \in S$.
    \end{itemize}

    Folgerungen:
    \begin{itemize}
        \item Für jede Folge $E_1, E_2, \ldots \in S$ ist $\bigcap_{E_i \in \Omega} E_i \in S$.
        \item $\emptyset \in S$ und $\Omega \in S$.
        \item Für jede nichtleere Menge $\Omega$ ist die Potenzmenge $\Pot(\Omega)$ eine Ereignisalgebra über $\Omega$.
    \end{itemize}

    Ist $\Omega$ endlich oder abzählbar unendlich, wählt man als Ereignisalgebra stets die Potenzmenge.
\end{defi}

\begin{bonus}{Kolmogoroff-Axiome}
    Es sei $\Omega$ eine Ergebnismenge und $S$ eine Ereignisalgebra über $\Omega$.
    Eine Zuordnungsvorschrift $P: S \to \R$ heißt \emph{Wahrscheinlichkeitsmaß}, wenn gilt:
    \begin{enumerate}
        \item $\forall E \in S: 0 \leq P(E) \leq 1$.
        \item $P(\Omega) = 1$
        \item Falls $E_1, E_2, \ldots$ disjunkte Ereignisse sind, gilt
              \[
                  P \left( \bigcup_{i} E_i \right) = \sum_{i} P(E_i) \quad \text{\enquote{$\sigma$-Additivität}}
              \]
    \end{enumerate}

    Das Tripel $(\Omega, S, P)$ mit $\Omega$ als Ergebnismenge, $S$ als Ereignisalgebra und $P$ als Wahrscheinlichkeitsmaß bezeichnet man als \emph{Wahrscheinlichkeitsraum}.
\end{bonus}

\begin{defi}{Bedingte Wahrscheinlichkeit}
    In vielen Anwendungen ist das Eintreten eines Ereignisses $A$ nicht unabhängig davon, ob vorher ein anderes Ereignis $B$ eingetreten ist oder nicht.
    Man spricht dann von einer \emph{bedingten Wahrscheinlichkeit} und schreibt $P(A \mid B)$.
    Es gilt:
    \[
        P(A \mid B) = \frac{P(A \cap B)}{P(B)}
    \]

    Generell gilt $P(A \mid B) \neq P(B \mid A)$, aber:
    \begin{alignat*}{1}
                       & P(A \mid B) = \frac{P(A \cap B)}{P(B)} = \frac{P(B \cap A)}{P(B)} = \frac{P(B \cap A)}{P(A)} \cdot \frac{P(A)}{P(B)} \\
        \implies \quad & P(A \mid B) = P(B \mid A) \cdot \frac{P(A)}{P(B)}
    \end{alignat*}

    Alle Axiome für eine Wahrscheinlichkeit werden von der bedingten Wahrscheinlichkeit erfüllt.
    Damit gilt auch:
    \begin{itemize}
        \item $E_1 \subseteq E_2 \implies P(E_1 \mid B) \leq P(E_2 \mid B)$
        \item $P(\conj{A} \mid B) = 1 - P(A \mid B)$
    \end{itemize}
\end{defi}

\begin{defi}{Multiplikationssatz}
    Löst man die Definition der bedingten Wahrscheinlichkeit auf nach der Wahrscheinlichkeit für das gleichzeitige Eintreten zweier Ereignisse $A$ und $B$, so ergibt sich der \emph{Multiplikationssatz} der Wahrscheinlichkeitsrechnung:
    \[
        P(A \cap B) = P(A \mid B) \cdot P(B) = P(B \mid A) \cdot P(A)
    \]
    bzw.
    \[
        P(A \cap B \cap C) = P(A) \cdot P(B \mid A) \cdot P(C \mid A \cap B)
    \]
\end{defi}

\begin{defi}{Stochastische Unabhängigkeit}
    In einigen Anwendungen ist die Wahrscheinlichkeit für das Eintreten des Ereignisses $A$ unabhängig davon, ob $B$ eingetreten ist oder nicht:
    \[
        P(A \mid B) = P(A \mid \conj{B}) = P(A)
    \]
    Aus dem Multiplikationssatz ergibt sich damit als Definition für die \emph{stochastische Unabhängigkeit} zweier Ereignisse $A$ und $B$:
    \[
        P(A \cap B) = P(A) \cdot P(B)
    \]
\end{defi}

\begin{bonus}{Vierfeldertafel}
    \begin{center}
        \begin{tabular}{C|CC|C}
                                & B                  & \conj{B}                  & \text{Zeilensumme} \\
            \hline
            A                   & P(A \cap B)        & P(A \cap \conj{B})        & P(A)               \\
            \conj{A}            & P(\conj{A} \cap B) & P(\conj{A} \cap \conj{B}) & P(\conj{A})        \\
            \hline
            \text{Spaltensumme} & P(B)               & P(\conj{B})               & 1
        \end{tabular}
    \end{center}

    Bei vollständiger Unabhängigkeit der Ereignisse $A$ und $B$ voneinander gilt:

    \begin{center}
        \begin{tabular}{C|CC|C}
                                & B                      & \conj{B}                      & \text{Zeilensumme} \\
            \hline
            A                   & P(A) \cdot P(B)        & P(A) \cdot P(\conj{B})        & P(A)               \\
            \conj{A}            & P(\conj{A}) \cdot P(B) & P(\conj{A}) \cdot P(\conj{B}) & P(\conj{A})        \\
            \hline
            \text{Spaltensumme} & P(B)                   & P(\conj{B})                   & 1
        \end{tabular}
    \end{center}
\end{bonus}

\begin{bonus}{Zusammenhangskoeffizient}
    Der \emph{Zusammenhangskoeffizient} bzw. das \emph{Assoziationsmaß} $Q \in [-1 ; 1]$ sei definiert als:
    \[
        Q = \frac{P(A \cap B) \cdot P(\conj{A} \cap \conj{B}) - P(A \cap \conj{B}) \cdot P(\conj{A} \cap B)}{P(A \cap B) \cdot P(\conj{A} \cap \conj{B}) + P(A \cap \conj{B}) \cdot P(\conj{A} \cap B)}
    \]
\end{bonus}

\begin{defi}{Mehrstufiges Zufallsexperiment}
    Kompliziertere Zufallsprozesse bestehen häufig aus mehreren nacheinander ablaufenden Zufallsexperimenten bzw. einem \emph{mehrstufigen Zufallsexperiment}.

    Ein wichtiges Hilfsmittel dabei sind \emph{Ereignisbäume}.
\end{defi}

\begin{example}{Ereignisbaum}
    TO DO
\end{example}

\begin{defi}{Totale Wahrscheinlichkeit}
    Sind nur bedingte Wahrscheinlichkeiten und die Wahrscheinlichkeiten des bedingenden Ereignisses bekannt, ergibt sich die totale Wahrscheinlichkeit von $B$ aus:
    \[
        P(B) = \sum_{i=1}^n P(A_i) \cdot P(B \mid A_i)
    \]

    TO DO (Graph, siehe Folie 67)
\end{defi}

\begin{defi}{Bayes'sche Formel}
    Für den Zusammenhang zwischen $P(A \mid B)$ und $P(B \mid A)$ ergibt sihc direkt aus der Definition und dem Multiplikationssatz die \emph{Bayes'sche Formel} bzw. der \emph{Satz von Bayes}:
    \[
        P(A \mid B) = \frac{P(A \cap B)}{P(B)} = \frac{P(B \cap A)}{P(B)} = \frac{P(B \mid A) \cdot P(A)}{P(B)} = \frac{P(B \mid A) \cdot P(A)}{\sum_{i=1}^n P(A_i) \cdot P(B \mid A_i)}
    \]

    Die Wahrscheinlichkeit, dass $B$ über einen bestimmten Pfad eintritt, ergibt sich als Verhältnis der Wahrscheinlichkeit für diesen Pfad zur totalen Wahrscheinlichkeit von $B$.
\end{defi}

\subsection{Wahrscheinlichkeitsverteilung einer Zufallsvariablen}

\begin{defi}{Zufallsvariable}
    Eine \emph{Zufallsvariable} $X$ ordnet jedem Elementarereignis aus der Ergebnismenge eindeutig eine reelle Zahl zu, bildet also die Ergebnismenge auf die Menge der reellen Zahlen ab:
    \[
        X: \Omega \to \R
    \]
    $X$ ist somit eine reellwertige Funktion mit
    \begin{itemize}
        \item Definitionsbereich: $D = \Omega$
        \item Wertebereich: $W_X = \{ X \mid X = X(\omega) \land \omega \in \Omega \}$
    \end{itemize}

    $X$ heißt \emph{diskret}, wenn $W_X$ endlich viele oder abzählbar unendlich viele reelle Werte enthält.

    $X$ heißt \emph{stetig}, wenn $W_X$ überabzählbar unendlich viele reelle Werte enthält.
\end{defi}

\begin{defi}{Verteilungsfunktion}
    $X$ sei eine Zufallsvariable.
    Die Funktion ($F_X: \R \to [0;1]$)
    \[
        \forall x \in \R: F_X(x) := P(\{ \omega \in \Omega \mid X(\omega) \leq x \}) := P(X \leq x)
    \]
    heißt \emph{Verteilungsfunktion} der Zufallsvariablen $X$.

    Anschaulich:
    $F_X(x)$ (oft nur $F(x)$) ist die Wahrscheinlichkeit dafür, dass die Zufallsvariable $X$ einen Wert $\leq x$ annimmt (höchstens $x$).

    Verteilungsfunktionen besitzen folgende Eigenschaften:
    \begin{enumerate}
        \item $F(x)$ ist eine monoton wachsende Funktion mit $0 \leq F(x) \leq 1$.
        \item $\lim_{x \to -\infty} F(x) = 0$ (unmögliches Ereignis)
        \item $\lim_{x \to \infty} F(x) = 1$ (sicheres Ereignis)
        \item $P(a < X \leq b) = F(b) - F(a)$
    \end{enumerate}
\end{defi}

\begin{defi}{Wahrscheinlichkeitsverteilung einer diskreten Zufallsvariablen}
    Bei einer diskreten Zufallsvariablen $X$ gehört zu jedem Wert $x_i$, den sie annehmen kann, eine bestimmte Wahrscheinlichkeit:
    \[
        P(X = x_i) = p_i
    \]
    Damit ist die \emph{Wahrscheinlichkeitsfunktion} einer diskreten Verteilung gegeben mit
    \[
        f(x) =
        \begin{cases}
            p_i & \text{für} \ x = x_i \\
            0   & \text{sonst}
        \end{cases}
    \]

    Die zugehörige Verteilungsfunktion ist dann
    \[
        F(x) = P(X \leq x) = \sum_{x_i \leq x} f(x_i)
    \]

    Anschaulich:
    $f(x)$ ist die Wahrscheinlichkeit dafür, dass die Zufallsvariable $X$ den Wert $x$ annimmt (genau $x$).

    Die Wahrscheinlichkeitsfunktion $f(x)$ und die Verteilungsfunktion $F(x)$ besitzen folgende Eigenschaften:
    \begin{enumerate}
        \item $f(x_i) \geq 0$
        \item $f(x)$ ist normiert, d.h. es gilt:
              \[
                  \sum_{i=1}^{\infty} f(x_i) = 1
              \]
        \item $F(x)$ ist eine monoton wachsende Funktion mit $0 \leq F(x) \leq 1$.
        \item $F(a < X \leq b) = F(b) - F(a)$
    \end{enumerate}
\end{defi}

\begin{defi}{Wahrscheinlichkeitsverteilung einer stetigen Zufallsvariablen}
    Die Wahrscheinlichkeitsverteilung einer stetigen Zufallsvariablen $X$ lässt sich durch die \emph{Dichtefunktion} $f(x)$ oder durch die zugehörige Verteilungsfunktion
    \[
        F(x) = P(X \leq x) = \int_{-\infty}^{x} f(u) \diff u
    \]
    vollständig beschreiben.

    Die Dichtefunktion $f(x)$ und die Verteilungsfunktion $F(x)$ besitzen folgende Eigenschaften:
    \begin{enumerate}
        \item $f(x_i) \geq 0$
        \item $f(x)$ ist normiert, d.h. es gilt:
              \[
                  \int_{-\infty}^{\infty} f(x) \diff x = 1
              \]
        \item $F(x)$ ist eine monoton wachsende Stammfunktion der Dichtefunktion $f(x)$, d.h. es gilt
              \[
                  \frac{\diff F(x)}{\diff x} = f(x)
              \]
        \item $F(a \leq X \leq b) = \int_a^b f(x) \diff x = F(b) - F(a)$
    \end{enumerate}
\end{defi}

\begin{defi}{Transformierte Zufallsvariable}
    Wenn eine reelle Zufallsvariable $X$ auf dem Ergebnisraum $\Omega$ und eine Funktion $g : \R \to \R$ gegeben ist, dann ist auch $Y = g(X)$ eine Zufallsvariable auf demselben Ergebnisraum.

    $g(X)$ wird auch als \emph{Transformation der Zufallsvariablen} $X$ unter $g$ bezeichnet.

    Die Verteilungsfunktion von $Y$ lautet dann
    \[
        F_Y(y) = P(g(X) \leq y)
    \]

    Beispiele:
    \begin{itemize}
        \item Lineare Transformation:
              \[
                  g_1(X) = aX + b
              \]
        \item Betragsfunktion bzw. Gleichrichter:
              \[
                  g_2(X) = \abs{X}
              \]
        \item Energiefunktion:
              \[
                  g_3(X) = aX^2
              \]
    \end{itemize}
\end{defi}

\begin{algo}{Transformation der Verteilungsfunktion}
    Sei $g$ streng monoton wachsend auf dem Wertebereich von $X$.
    Dann gilt für die Verteilungsfunktion:
    \[
        F_Y(y) = P(\{ \omega \in \Omega \mid Y(\omega) \leq y \}) = P(\{ \omega \in \Omega \mid X(\omega) \leq g^{-1}(y) \}) = F_X(g^{-1}(y))
    \]

    Für eine lineare Transformation gilt damit:
    \[
        Y = g(X) = aX + b \quad \implies \quad F_Y(y) = F_X(g^{-1}(y)) = F_X\left( \frac{y-b}{a} \right)
    \]
\end{algo}

\begin{algo}{Transformation der Dichtefunktion}

    Falls $F_Y(y)$ geschlossen darstellbar ist, gilt für die Dichtefunktion:
    \[
        f_Y(y) = \frac{\diff F_Y(y)}{\diff y} = f_X(x) \cdot \frac{1}{g'(x)} = \frac{f_X(g^{-1}(y))}{g'(g^{-1}(y))}
    \]
    Für eine lineare Transformation gilt damit:
    \[
        F_Y(y) = F_X\left( \frac{y-b}{a} \right) \quad \implies \quad f_Y(y) = \frac{\diff}{\diff y} F_X \left( \frac{y-b}{a} \right) = f_X \left( \frac{y-b}{a} \right) \cdot \frac{1}{a}
    \]
\end{algo}

\begin{defi}{Erwartungswert}
    Der wichtigste Lageparameter einer Verteilung ist der \emph{Erwartungswert}. 
    Der Erwartungswert einer Zufallsvariablen beschreibt die Zahl, die die Zufallsvariable im Mittel annimmt.

    Für eine diskrete Zufallsvariable $X$ gilt: 
    \[ 
        \Mean(X) := \sum_i x_i \cdot P(X = x_i) \quad \text{bzw.} \quad \Mean(X) := \sum_i X(\omega_i) \cdot P(\{ \omega_i \}), \, \omega_i \in \Omega
    \]

    Für eine stetige Zufallsvariable $X$ gilt: (Schwerpunkt der Dichtefunktion)
    \[
        \Mean(X) = \int_{-\infty}^{\infty} x \cdot f(x) \diff x 
    \]

    Sehr oft wird statt $\Mean(X)$ auch $\mu$ oder $\mu_X$ geschrieben.
\end{defi}

\begin{algo}{Transformation des Erwartungswertes auf eine neue Zufallsvariable}
    Bei einer Transformation von einer Zufallsvariable $X$ auf eine neue Zufallsvariable $Y = g(X)$ gilt: 
    \[ 
        \Mean(Y) = \int_{-\infty}^{\infty} y \cdot f_Y(y) \diff y = \int_{-\infty}^{\infty} g(x) \cdot f_X(x) \diff x
    \]

    Speziell bei der linearen Transformation gilt: 
    \[ 
        \Mean(aX + b) = a \Mean(X) + b
    \]
\end{algo}

\begin{defi}{Median}
    Der \emph{Median} $\tilde{x}$ ist der Wert, der die Verteilung \enquote{halbiert}.

    Bei stetigen Zufallsvariablen existiert der Median immer und es gilt: 
    \[ 
        P(X \leq \tilde{x}) = F_X(\tilde{x}) = \int_{-\infty}^{\tilde{x}} f_X(x) \diff x = \frac{1}{2}
    \]

    Bei diskreten Zufallsvariablen gibt es nur wenige Ausnahmen, bei denen ein $x$-Wert existiert mit genau $F(x) = \frac{1}{2}$.
    Daher gilt folgende Definition: 
    \[ 
        P(X < \tilde{x}) \leq \frac{1}{2} \quad \land \quad P(X \leq \tilde{x}) \geq \frac{1}{2}
    \]
\end{defi}

\begin{defi}{Quantile}
    Ein \emph{Quantil} ist ein Lagemaß. 
    Ein bestimmter Anteil der Werte (einer Zufallsstichprobe) ist kleiner als das Quantil, der Rest ist größer. 
    Das 25\%-Quantil, bzw. das untere Quartil, beispielsweise ist der Wert, für den gilt, dass 25\% aller Werte $\leq$ sind als dieser Wert. 

    Bei stetigen Zufallsvariablen gilt: 
    \[ 
        P(X \leq x_\alpha) = F_X(x_\alpha) = \int_{-\infty}^{x_\alpha} f_X(x) \diff x = \alpha 
    \]

    Bei diskreten Zufallsvariablen gilt: 
    \[ 
        P(X < x_\alpha) \leq \alpha \quad \land \quad P(X \leq x_\alpha) \geq \alpha
    \]

    Relevant sind insbesondere das \emph{untere Quartil} ($\alpha = \nicefrac{1}{4}$), das \emph{obere Quartil} ($\alpha = \nicefrac{3}{4}$) und der Median ($\alpha = \nicefrac{1}{2}$).

    Der \emph{Quartilabstand} $x_{\nicefrac{3}{4}} - x_{\nicefrac{1}{4}}$ ist ein Streuungsmaß, denn im Intervall zwischen unterem und oberem Quartil liegen die \enquote{inneren} 50\% der Verteilung.
\end{defi}

\begin{defi}{Varianz}
    Die \emph{Varianz} ist ein wichtiges Maß für die Streuung der Wahrscheinlichkeitsdichte um ihren Schwerpunkt. 
    Mathematisch wird sie definiert als die mittlere quadratische Abweichung einer reellen Zufallsvariablen von ihrem Erwartungswert.

    Bei diskreten Zufallsvariablen gilt: 
    \[
        \sigma^2 = \Var(X) = \sum_i (x_i - \mu)^2 \cdot P(X = x_i)
    \]

    Bei stetigen Zufallsvariablen gilt: 
    \[
        \sigma^2 = \Var(X) = \int_{-\infty}^{\infty} (x - \mu)^2 \cdot f(x) \diff x 
    \]
\end{defi}

\begin{defi}{Standardabweichung}
    Die \emph{Stamdardabweichung} ist ein weiteres Streuungsmaß und wird definiert als die Quadratwurzel der Varianz: 
    \[
        \sigma = \sqrt{\Var(X)}
    \]
\end{defi}

\begin{algo}{Verschiebungssatz}
    Sei der Erwartungswert einer Zufallsvariable $X$ gegeben mit $\Mean(X) = \mu$.
    Dann gilt mit dem \emph{Verschiebungssatz} für ein beliebiges $a \in \R$: 
    \[ 
        \Mean((X-a)^2) = \Var(X) + (\mu - a)^2
    \]

    Für $a = 0$ erhalten wir eine alternative Formel zur Berechnung der Varianz: 
    \[ 
        \Var(X) = \Mean(X^2) -\Mean(X)^2 = \Mean(X^2) - \mu^2
    \]
\end{algo}

\begin{defi}{Tschebyscheffsche Ungleichung}
    Mithilfe der \emph{Tschebyscheffschen Ungleichung} lässt sich unter Verwendung der existierenden ersten beiden Momente (Erwartungswert und Varianz) die Wahrscheinlichkeit dafür abschätzen, dass die Zufallsvariable $X$ Werte in bestimmten Intervallen der reellen Zahlengeraden annimmt, ohne jedoch die Verteilung von $X$ zu kennen. 
    
    Sie lautet für eine Zufallsvariable $X$ mit Erwartungswert $\mu$ und Varianz $\sigma^2$:

    \[
        P(\abs{X - \mu} \geq \epsilon) \leq \frac{\sigma^2}{\epsilon^2}
    \]

    Sie setzt keine besondere Verteilungsform voraus. 

    Ein Nachteil der Tschebyscheffschen Ungleichung ist, dass sie nur eine grobe Abschätzung liefert. 
\end{defi}

\subsection{Spezielle Wahrscheinlichkeitsverteilungen}

\begin{defi}{Gleichverteilung}
    Eine \emph{Gleichverteilung} beschreibt eine Wahrscheinlichkeitsverteilung mit bestimmten Eigenschaften. 

    Im diskreten Fall tritt jedes mögliche Ergebnis mit der gleichen Wahrscheinlichkeit ein, im stetigen Fall ist die Dichte konstant. 
    
    Für eine im Intervall $[a,b]$ stetige gleichverteilte Zufallsvariable $X$ gilt also:
    \[
        f(x) = 
        \begin{cases}
            \frac{1}{b-a}   & \text{für} \ x \in [a;b] \\ 
            0               & \text{sonst}
        \end{cases}
    \]
    \[
        F(x) = 
        \begin{cases}
            0 & \text{für} \ x \leq a \\ 
            \frac{x-a}{b-a} & \text{für} \ a < x \leq b \\ 
            1 & \text{für} \ x > b
        \end{cases}
    \]

    Der Grundgedanke einer Gleichverteilung ist, dass es keine Präferenz gibt. 
\end{defi}

\begin{defi}{Bernoulli-Experiment}
    Bei einem \emph{Bernoulli-Experiment} gibt es stets nur zwei Ausgänge, Treffer oder Niete. 
    Zudem muss die Wahrscheinlichkeit für einen Treffer, $p$, und somit auch die für eine Niete, $1-p$, bei jedem der Experimente dieselbe sein. 

    Bei einem \emph{Bernoulli-Experiment vom Umfang $n$} wird ein Bernoulli-Experiment $n$-fach ausgeführt mit der Voraussetzung, dass die Ergebnisse der einzelnen Studen voneinander unabhängig sind.
\end{defi}

\begin{defi}{Binomialverteilung}
    Ein Bernoulli-Experiment mit den beiden sich gegenseitig ausschließenden Ergebnissen $A$ und $\conj{A}$ werde $n$-mal nacheinander ausgeführt (Bernoulli-Experiment mit Umfang $n$).

    Dann genügt die diskrete Zufallsvariable
    \[ 
        X = \text{Anzahl der Versuche, in denen das Ereignis $A$ eintritt}
    \]
    der \emph{Binomialverteilung} mit der Wahrscheinlichkeitsfunktion 
    \[ 
        f(x) = P(X = x) = \binom{n}{x} \cdot p^x \cdot q^{n-x} \qquad x \in [0,n]
    \]
    und der zugehörigen Verteilungsfunktion 
    \[ 
        F(x) = P(X \leq x) = \sum_{k \leq x} \binom{n}{k} \cdot p^k \cdot q^{n-k} \qquad x \geq 0
    \]
    (für $x < 0$ ist $F(x) = 0$) $n$ und $p$ sind dabei die Parameter der Binomialverteilung.

    Die Maßzahlen dieser Verteilung lauten: 
    \begin{itemize}
        \item Erwartungswert: $\mu = np$
        \item Varianz: $\sigma^2 = npq = np(1-p)$
        \item Standardabweichung: $\sigma = \sqrt{npq} = \sqrt{np(1-p)}$
    \end{itemize}

    Man schreibt auch $X \sim B(n,p)$.
\end{defi}

\begin{example}{Binomialverteilung}
    \begin{center}
        \includegraphics[width=.7\linewidth]{includes/figures/example_binomialverteilung_bar}
    \end{center}
\end{example}

\begin{defi}{Hypergeometrische Verteilung}
    Die \emph{hypergeometrische Verteilung} beschreibt die Wahrscheinlichkeit dafür, dass bei $N$ gegebenen Elementen (Grundgesamtheit des Umfangs $N$), von denen $M$ die gewünschte Eigenschaft besitzen, beim Herausgreifen von $n$ Probestücken (Stichprobe des Umfangs $n$) genau $x$ Treffer erzielt werden, d. h. die Wahrscheinlichkeit für $X = x$ Erfolge in $n$ Versuchen. 

    Dabei ist die Wahrscheinlichkeitsfunktion 
    \[ 
        f(x) = P(X = x) = \frac{\binom{M}{x} \binom{N-M}{n-x}}{\binom{N}{n}} \qquad x \in [0,n]
    \]

    und die zugehörige Verteilungsfunktion
    \[
        F(x) = P(X \leq x) = \sum_{k\leq x} \frac{\binom{M}{k} \binom{N-M}{n-k}}{\binom{N}{n}} \qquad x \geq 0
    \]
    (für $x < 0$ ist $F(x) = 0$) $N$, $M$ und $n$ sind dabei die Parameter der hypergeometrischen Verteilung. 

    Die Maßzahlen dieser Verteilung lauten: 
    \begin{itemize}
        \item Erwartungswert: $\mu = n \cdot \frac{M}{N}$
        \item Varianz: $\sigma^2 = n \cdot \frac{M}{N} \cdot \left( 1 - \frac{M}{N}\right) \cdot \frac{N-n}{N-1} = \frac{nM(N-M)(N-n)}{N^2(N-1)}$ 
    \end{itemize}

    Man schreibt auch $X \sim H(N,M,n)$.
\end{defi}

\begin{example}{Hypergeometrische Verteilung}
    \begin{center}
        \includegraphics[width=.7\linewidth]{includes/figures/example_hypergeom_verteilung_bar}
    \end{center}
\end{example}

\begin{defi}{Poisson-Verteilung}
    Die \emph{Poisson-Verteilung} ist eine Wahrscheinlichkeitsverteilung, mit der die Anzahl von Ereignissen modelliert werden kann, die bei konstanter mittlerer Rate unabhängig voneinander in einem festen Zeitintervall oder räumlichen Gebiet eintreten. 

    Die Wahrscheinlichkeitsfunktion einer diskreten poisson-verteilten Zufallsvariablen $X$ ist gegeben mit 
    \[
        f(x) = P(X = x) = \frac{\mu^x}{x!} \cdot e^{-\mu} \qquad x \in [0,\infty]
    \]  
    und die zugehörige Verteilungsfunktion mit 
    \[ 
        F(x) = P(X \leq x) = e^{-\mu} \cdot \sum_{k \leq x} \frac{\mu^k}{k!} \qquad x \geq 0
    \]
    (für $x < 0$ ist $F(x) = 0$) $\mu$ ist dabei der Parameter der Poisson-Verteilung.

    Die Maßzahlen dieser Verteilung lauten: 
    \begin{itemize}
        \item Erwartungswert: $\mu$
        \item Varianz: $\sigma^2 = \mu$
        \item Standardabweichung: $\sigma = \sqrt{\mu}$
    \end{itemize}

    Man schreibt auch $X \sim \Poi(\mu)$.
\end{defi}

\begin{example}{Poisson-Verteilung}
    \begin{center}
        \includegraphics[width=.7\linewidth]{includes/figures/example_poisson_verteilung_bar}
    \end{center}
\end{example}

\begin{defi}{Lokaler Grenzwertsatz von de Moivre-Laplace}
    Nach dem \emph{lokalen Grenzwertsatz von de Moivre-Laplace} konvergiert die Binomialverteilung für den Stichprobenumfang $n \to \infty$ und Wahrscheinlichkeiten $0 < p < 1$ gegen die Normalverteilung. 
    Bei großem Stichprobenumpfang kann daher die Normalverteilung als Näherung der Binomialverteilung verwendet werden. 

    Also gilt ($\sigma^2 = p(1-p)$): 
    \[
        B(k \mid p, n) = \binom{n}{k} \cdot p^k \cdot (1-p)^{n-k} \approx \frac{1}{2\pi n \sigma^2} \cdot \exp \left( -\frac{n}{2\sigma^2} \left( \frac{k}{n} - p \right)^2 \right) 
    \]
\end{defi}

\begin{defi}{Normalverteilung}
    Die \emph{Normalverteilung} ist eine der wichtigsten stetigen Wahrscheinlichkeitsverteilungen.

    %Die besondere Bedeutung der Normalverteilung beruht unter anderem auf dem zentralen Grenzwertsatz, dem zufolge Verteilungen, die durch additive Überlagerung einer großen Zahl von unabhängigen Einflüssen entstehen, annähernd normalverteilt sind.

    Eine stetige Zufallsvariable $X$ hat eine Normalverteilung mit Erwartungswert $\mu \neq \pm \infty$ und Varianz $\sigma^2 > 0$, oft geschrieben als $X \sim \mathcal{N} \left(\mu ,\sigma^{2}\right)$, wenn $X$ die folgende Wahrscheinlichkeitsdichte hat:
    
    \[
        f(x) = P(X = x) = \frac{1}{\sqrt{2\pi n \sigma^2}} \cdot \exp \left( - \frac{(x-\mu)^2}{2\sigma^2} \right) \qquad x \in \R
    \]

    Die zugehörige Verteilungsfunktion ist dann gegeben mit 
    \[ 
        F(x) = P(X \leq x) = \frac{1}{\sigma\sqrt{2\pi}} \int_{-\infty}^x e^{\left( \frac{t-\mu}{\sigma} \right)^2} \diff t
    \]

    Wichtige Eigenschaften der Normalverteilung sind: 
    \begin{itemize}
        \item $f(x)$ ist symmetrisch um $x = \mu$
        \item $f(x)$ hat ein Maximum der Höhe $\nicefrac{1}{\sigma\sqrt{2\pi}}$ bei $x = \mu$
        \item $f(x)$ hat Wendepunkte bei $x = \mu \pm \sigma$
        \item $F(x)$ ist nicht geschlossen lösbar!
    \end{itemize}
\end{defi}

\begin{example}{Normalverteilung}
    \begin{center}
        \includegraphics[width=.7\linewidth]{includes/figures/example_normalverteilung}
    \end{center}
\end{example}

\begin{defi}{Standardnormalverteilung}
    Die \emph{Standardnormalverteilung} ist eine spezielle Variante der Normalverteilung.
    Dabei gilt $\mu = 0$, $\sigma^2 = 1$, bzw. $X \sim \mathcal{N}(0,1)$. 

    Wichtige Eigenschaften der Standardnormalverteilung sind: 
    \begin{itemize}
        \item Jede Normalverteilung lässt sich auf die Standardnormalverteilung transformieren.
        \item Die Verteilungsfunktion $\Phi(x)$ der Standardnormalverteilung ist tabelliert.
    \end{itemize}
\end{defi}

\begin{algo}{Transformation auf standardisierte Variable}
    Sei $X \sim \mathcal{N}(\mu,\sigma^2)$. 
    Dann gilt: 
    \[
        P(X \leq x) = F(x) = \Phi \left( \frac{x-\mu}{\sigma} \right) = \Phi (u)
    \]
    wobei $u = \frac{x-\mu}{\sigma}$ eine standardisierte Variable ist.

    Dabei gilt:
    \begin{itemize}
        \item $P(X \geq x) = 1 - \Phi(u)$
        \item $P(a \leq X \leq b) = \Phi \left( \frac{a - \mu}{\sigma} \right) - \Phi \left( \frac{a - \mu}{\sigma} \right)$
        \item $\Phi(-u) = 1 - \Phi(u)$
    \end{itemize}
\end{algo}

\begin{bonus}{Geometrische Verteilung}
    Die \emph{geometrische Verteilung} beschreibt das \enquote{Warten auf den ersten Erfolg}. 

    Dabei besitzt eine diskrete Zufallsvariable $X$ eine geometrische Verteilung mit Parameter $0 < p < 1$, falls ihre Verteilung gegeben ist durch 
    \[
        f(x) = P(X = x) = (1-p)^xp \qquad x \in \N_0
    \]

    $X$ beschreibt dann die Anzahl der \enquote{Nieten} vor dem ersten \enquote{Treffer}, der mit der Wahrscheinlichkeit $p$ eintritt.

    Die Maßzahlen dieser Verteilung lauten: 
    \begin{itemize}
        \item Erwartungswert: $\mu = \frac{1-p}{p}$
        \item Varianz: $\sigma^2 = \frac{1-p}{p^2}$
    \end{itemize}
\end{bonus}

\begin{example}{Geometrische Verteilung}
    \begin{center}
        \includegraphics[width=.7\linewidth]{includes/figures/example_geom_verteilung_bar}
    \end{center}
\end{example}

\begin{algo}{Approximation von Verteilungen}

    \begin{center}
        \begin{tabularx}{\linewidth}{|>{\hsize=.6\hsize}X|X|X|>{\hsize=1.4\hsize}X|}
        \hline
        & \multicolumn{3}{l|}{Approximation durch eine $\ldots$} \\ \cline{2-4}
        & Binomialverteilung & Poisson-Verteilung & Normalverteilung \\ 
        \hline
        Binomial-verteilung & & \makecell[c]{ \textbf{Bedingungen:} \\ $np \leq 10$ \\ $n \geq 1500p$ \\ \\ \textbf{Dann gilt:} \\ $\approx \Poi(np)$ } & \makecell[c]{ \textbf{Bedingungen:} \\ $np(1-p) > 9$ \\ \\ \textbf{Dann gilt:} \\ $\approx \mathcal{N}(np, np(1-p))$ } \\ 
        \hline
        Hypergeo-metrische Verteilung & \makecell[c]{ \textbf{Bedingungen:} \\ $0.1 < \frac{M}{N} < 0.9$ \\ $n < 0.05N$, $n > 10$ \\ \\ \textbf{Dann gilt:} \\ $\approx B(n,\frac{M}{N})$} & \makecell[c]{ \textbf{Bedingungen:} \\ $0.1 \not< \frac{M}{N} \not< 0.9$ \\ $n < 0.05N$, $n > 30$ \\ \\ \textbf{Dann gilt:} \\ $\approx \Poi(n \frac{M}{N})$ } & \makecell[c]{ \textbf{Bedingungen:} \\ $0.1 < \frac{M}{N} < 0.9$ \\ $n < 0.05N$, $n > 30$ \\ \\ \textbf{Dann gilt:} \\ $\approx \mathcal{N}(n \frac{M}{N},n \frac{M}{N}(1-\frac{M}{N}) \frac{N-n}{N-1})$ } \\ 
        \hline
        Poisson-Verteilung & & & \makecell[c]{ \textbf{Bedingungen:} \\ $\mu > 9$ \\ \\ \textbf{Dann gilt:} \\ $\approx \mathcal{N} (\mu, \sqrt{\mu})$} \\ 
        \hline
        \end{tabularx}
    \end{center}

    \vspace{1em}
    \emph{Achtung}:

    Diskrete Verteilungen nehmen nur einzelne Werte an, stetige Verteilungen haben positive Wahrscheinlichkeit nur für Intervalle - Wenn wir also die diskrete Verteilung durch eine Stetige approximieren wollen, müssen wir aus dem einzelnen Wert $a$ ein Intervall machen.

    Weil diskrete Verteilungen oft Werte aus den ganzen Zahlen annehmen, teilt man die Intervalle zwischen den einzelnen Zahlen einfach gerecht auf.

    So wird aus $a$ das Intervall $[a-0.5,a+0.5]$ und wir betrachten bei der Approximation 
    \[ 
        P(a-0.5 \leq X \leq a+0.5) \ \text{statt} \ P(a)
    \] 
\end{algo}

\begin{bonus}{Zusammenfassung von Verteilungsfunktionen}

\begin{center}
    \begin{tabularx}{\linewidth}{|>{\hsize=.15\hsize}X|>{\hsize=.15\hsize}X|>{\hsize=.35\hsize}X|>{\hsize=.1\hsize}X|>{\hsize=.3\hsize}X|}
        \hline
        Verteilung & Parameter & Wahrscheinlichkeits- bzw. Dichtefunktion & Art & Kennzahlen \\ 
        \hline 
        Binomial-verteilung $B(n,p)$ & \makecell[l]{$n \in \N$ \\ $0 < p < 1$} & \[ f(x) = \binom{n}{x}p^x(1-p)^{n-x} \] & diskret & \makecell[l]{$\mu = np$ \\ $\sigma^2 = np(1-p)$} \\
        \hline 
        Hypergeo-metrische Verteilung $H(N,M,n)$ & \makecell[l]{$N \in \N$ \\ $M \in [0,N]$ \\ $n \in [0,N]$} & \[ f(x) = \frac{\binom{M}{x} \binom{N-M}{n-x}}{\binom{N}{n}} \] & diskret & \makecell[l]{$\mu = n\frac{M}{N}$ \\ $\sigma^2 = n\frac{M}{N}\left( 1 - \frac{M}{N} \right) \frac{N-n}{N-1}$} \\ 
        \hline 
        Poisson-Verteilung $\Poi(\mu)$ & $\mu > 0$ & \[ f(x) = \frac{\mu^x}{x!} \cdot e^{-\mu} \] & diskret & \makecell[l]{$\mu = \mu$ \\ $\sigma^2 = \mu$} \\ 
        \hline
        (Gaußsche) Normal-verteilung $\mathcal{N} (\mu, \sigma^2)$ & \makecell[l]{$\mu \in \R$ \\ $\sigma^2 > 0$} & \[ f(x) = \frac{1}{\sqrt{2\pi} \cdot \sigma} \cdot e^{-\frac{1}{2}\left( \frac{x-\mu}{\sigma} \right)^2} \] & stetig & \makecell[l]{$\mu = \mu$ \\ $\sigma^2 = \sigma^2$} \\ 
        \hline
        Standard-normal-verteilung $\mathcal{N} (0,1)$ & \makecell[l]{$\mu = 0$ \\ $\sigma^2 = 1$} & \[ \phi(u) = \frac{1}{\sqrt{2\pi}} \cdot e^{-\frac{1}{2} u^2} \] & stetig & \makecell[l]{$\mu = 0$ \\ $\sigma^2 = 1$} \\ 
        \hline
    \end{tabularx}
\end{center}

\end{bonus}

\subsection{Mehrdimensionale Zufallsvariablen}

\begin{defi}{Wahrscheinlichkeitsfunktion einer zweidimensionalen Verteilung}
    Die \emph{Wahrscheinlichkeitsfunktion einer zweidimensionalen Verteilung} ist eine Funktion von zwei unabhängigen Variablen: 
    \[ 
        f(x,y) = P(X = x, Y = y)
    \]
\end{defi}

\begin{defi}{Randverteilung}
    Die beiden eindimensionalen Wahrscheinlichkeitsfunktiontn $f_1(x)$ und $f_2(y)$ der Zufallsvariablen $X$ und $Y$ werden als \emph{Randverteilungen} der zweidimensionalen Verteilung $(X,Y)$ bezeichnet.

    Es gilt: 
    \[ 
        f_1(x) = \sum_{y} f(x,y) 
    \] 
    \[ 
        f_2(y) = \sum_{x} f(x,y) 
    \] 
\end{defi}

\begin{example}{Zweidimensionale Zufallsvariable}
    Wir betrachten einen gleichzeitigen Wurf einer Münze und eines Würfels. 
    Dabei seien die Zufallsvariablen $X$ und $Y$ wie folgt:
    \[ 
        X = \text{\enquote{Anzahl Wappen bei der Münze}} \in \{ 0,1 \}
    \]
    \[ 
        Y = \text{\enquote{Augenzahl beim Würfeln}} \in \{ 1,2,3,4,5,6 \}
    \]

    Dann gibt es für die zweidimensionale Zufallsvariable $(X,Y)$ offensichtlich 12 Elementareignisse:
    
    \begin{center}
        \begin{tabular}{|C|C|C|C|C|C|C|}
            \hline
            $\diagbox{X}{Y}$ & 1 & 2 & 3 & 4 & 5 & 6  \\ 
            \hline 
            0 & (0,1) & (0,2)  & (0,3)  & (0,4)  & (0,5)  & (0,6) \\   
            \hline 
            1 & (1,1) & (1,2)  & (1,3)  & (1,4)  & (1,5)  & (1,6) \\   
            \hline 
        \end{tabular}
    \end{center}

    und es gilt die zweidimensionale Wahrscheinlichkeitsfunktion (Verteilungstabelle):

    \begin{center}
        \begin{tabular}{|C|C|C|C|C|C|C||C|}
            \hline
            $\diagbox{X}{Y}$ & 1 & 2 & 3 & 4 & 5 & 6 & f_1(x)  \\ 
            \hline 
            0 & \nicefrac{1}{12} & \nicefrac{1}{12}  & \nicefrac{1}{12}  & \nicefrac{1}{12}  & \nicefrac{1}{12}  & \nicefrac{1}{12} & \nicefrac{1}{2} \\   
            \hline 
            1 & \nicefrac{1}{12} & \nicefrac{1}{12}  & \nicefrac{1}{12}  & \nicefrac{1}{12}  & \nicefrac{1}{12}  & \nicefrac{1}{12} & \nicefrac{1}{2} \\      
            \hline 
            \hline 
            f_2(y) & \nicefrac{1}{6} & \nicefrac{1}{6} & \nicefrac{1}{6} & \nicefrac{1}{6} & \nicefrac{1}{6} & \nicefrac{1}{6} & 1 \\ 
            \hline 
        \end{tabular}
    \end{center}
\end{example}

\begin{defi}{Verteilungsfunktion einer zweidimensionalen Verteilung}
    Die Wahrscheinlichkeitsfunktion einer zweidimensionalen Verteilung $(X,Y)$ lässt sich vollständig durch die Verteilungsfunktion darstellen. 

    Für die \emph{Verteilungsfunktion} 
    \[
        F(x,y) = P(X \leq x, Y \leq y) 
    \]
    
    gelten folgende Eigenschaften:
    \begin{itemize}
        \item $\lim_{x\to \infty, y\to \infty} F(x,y) = 1$ 
        \item $\lim_{x \to -\infty} F(x,y) = \lim_{y \to -\infty} F(x,y) = 0$
        \item $P(a < x \leq b, c < Y \leq d) = F(b,d) - F(a,d) - F(b,c) + F(a,c)$
    \end{itemize}
\end{defi}

\begin{defi}{Diskrete zweidimensionale Verteilung}
    $(X,Y)$ heißt \emph{diskret}, wenn beide Komponenten diskrete Zufallsvariablen sind. 

    TO DO
\end{defi}

\begin{defi}{Stetige zweidimensionale Verteilung}
    $(X,Y)$ heißt \emph{stetig}, wenn beide Komponenten stetige Zufallsvariablen sind. 

    TO DO
\end{defi}

\begin{defi}{Stochastisch unabhängige Zufallsvariable}
    Die Zufallsvariablen $X$ und $Y$ mit den Verteilungsfunktionen $F_1(x)$ und $F_2(y)$ und der gemeinsamen Verteilungsfunktion $F(x,y)$ heißen \emph{stochastisch unabhängig}, wenn die Bedingung
    \[
        F(x,y) = F_1(x) \cdot F_2(y)
    \]
    für alle $(x,y)$ erfüllt ist.

    Es gilt: 
    \begin{itemize}
        \item Ist die Bedingung nicht erfüllt, sind die Zufallsvariablen stochastisch abhängig. 
        \item Ist die Bedingung erfüllt, sind die beiden Ereignisse $X = x$ und $Y = y$ stochastisch unabhängig. 
        \item Sind $X$ und $Y$ stochastisch unabhängige Zufallsvariablen, so gilt $f(x,y) = f_1(x) \cdot f_2(y)$ 
        \item Sinngemäße Erweiterung auf $n$ Zufallsvariablen 
    \end{itemize}
\end{defi}

\begin{algo}{Summen von Zufallsgrößen}
    Die neue Zufallsvariable wird als Summe von anderen Zufallsvariablen definiert: 
    \[
        Z := X_1 + X_2 + \ldots + X_n
    \]

    Den Zahlenwerten $x_1 := X_1(\omega)$, $\ldots$, $x_n := X_n(\omega)$ eines Zufallsversuches mit Resultat $\omega$ wird die Zahl $z := x_1 + \ldots + x_n$ als Ergebnis $Z(\omega)$ der neuen Zufallsgröße $Z$ zugeordnet.

    Sei $Z = X + Y$. 

    Dann gilt im diskreten Fall 
    \[
        P(Z = z) = \sum_i P(X = x_i, Y = z - x_i)
    \]
    und im stetigen Fall
    \[ 
        f_Z(z) = \int_{-\infty}^{\infty} f_{XY}(x,z-x) \diff x
    \]

    Sind $X$ und $Y$ stohastisch unabhängig, dann gilt insbesondere 
    \[ 
        f_Z(z) = \int_{-\infty}^{\infty} f_X(x) \cdot f_Y(z-x) \diff x
    \]
    Das wird auch als \enquote{Faltung} bezeichnet.
\end{algo}

\begin{algo}{Produkt und Quotient zweier stetiger Zufallsgrößen}
    Sei $Z = XY$.
    Dann gilt:
    \[ 
        f_Z(z) = \int_{-\infty}^{\infty} f_{XY}(\nicefrac{z}{y}, y) \cdot \frac{1}{\abs{y}} \diff y 
    \]

    Sei $Z = \nicefrac{X}{Z}$.
    Dann gilt:
    \[ 
        f_Z(z) = \int_{-\infty}^{\infty} f_{XY}(zy,y) \cdot \abs{y} \diff y 
    \]
\end{algo}

\begin{algo}{Erwartungswert und Varianz für die Summe von Zufallsgrößen}
    $X$ und $Y$ seien als Funktionen auf $\Omega$ explizit bekannt:
    \[
        \implies (X+Y)(\omega) = X(\omega) + Y(\omega) \quad \land \quad (X \cdot Y)(\omega) = X(\omega) \cdot Y(\omega)
    \]

    Dann gilt für den Erwartungswert: 
    \[
        \forall \alpha \in \R: \Mean(\alpha X + b) = \alpha\Mean(X) + b 
    \]
    \[ 
        \Mean(\alpha X + \beta Y) = \alpha\Mean(X) + \beta\Mean(Y)
    \]

    Und für die Varianz:
    \[
        \forall \alpha \in \R: \Var(\alpha X + b) = \alpha^2 \Var(X)
    \]
    \[
        \Var(\alpha X + \beta Y) = \alpha^2 X + \beta^2 Y + 2\alpha\beta\Cov(X, Y) 
    \]

    Falls $X$ und $Y$ stochastisch unabhängige Zufallsvariablen sind, gilt: 
    \[
        \Mean(X \cdot Y) = \Mean(X) \cdot \Mean(Y) \implies \Cov(X, Y) = 0 \implies \Var(\alpha X + \beta Y) = \alpha^2 \Var(X) + \beta^2 \Var(Y)
    \]
\end{algo}

\subsection{Kovarianz und Korrelation}

\begin{defi}{Kovarianz}
        Die \emph{Kovarianz} ein Zusammenhangsmaß für einen monotonen Zusammenhang zweier Zufallsvariablen mit gemeinsamer Wahrscheinlichkeitsverteilung. 
        Der Wert dieser Kennzahl macht tendenzielle Aussagen darüber, ob hohe Werte der einen Zufallsvariablen eher mit hohen oder eher mit niedrigen Werten der anderen Zufallsvariablen einhergehen.

        Die Kovarianz ist definiert als: 
        \[
            \Cov(X, Y) = \Mean \left( (X - \Mean(X)) \cdot (Y - \Mean(Y)) \right)
        \]

        Es gilt: 
        \[
            \Cov(X, Y) = \Mean(XY) - \Mean(X)\Mean(Y)
        \]

        Eigenschaften der Kovarianz: 
        \begin{enumerate}
            \item $\Cov(X, Y) = \Cov(Y, X)$
            \item $\Cov(X, X) = \Var(X)$
            \item $\Cov(\alpha X + \beta, \gamma Y + \delta) = \alpha\gamma \cdot \Cov(X, Y)$
            \item $X$, $Y$ stochastisch unabhängig $\implies \Cov(X, Y) = 0$
            \item 
            \[
                \Cov \left( \sum_{i=1}^{m} \alpha_i X_i, \sum_{j=1}^{n} \beta_j Y_j \right) = \sum_{i=1}^{m} \sum_{j=1}^{n} \alpha_i \beta_j \Cov(X_i, Y_j)
            \]
        \end{enumerate}

        Zwei Zufallsvariablen $X$, $Y$ heißen \emph{unkorelliert}, falls $\Cov(X, Y) = 0$ ist.

        Im Allgemeinen darf aus der Unkorreliertheit zweier Zufallsvariablen nicht auf deren stochastische Unabhängigkeit geschlossen werden!
\end{defi}  

\begin{defi}{Korrelationskoeffizient}
    Der \emph{Person'sche Korrelationskoeffizient} ist ein Maß für den Grad des linearen Zusammenhangs zwischen zwei Zufallsvariablen. 
    Er kann Werte zwischen $-1$ und $+1$ annehmen. 
    Bei einem Wert von $+1$ (bzw. $-1$) besteht ein vollständig positiver (bzw. negativer) linearer Zusammenhang zwischen den betrachteten Merkmalen. 
    Wenn der Korrelationskoeffizient den Wert $0$ aufweist, hängen die beiden Merkmale überhaupt nicht linear voneinander ab. 
    Allerdings können diese ungeachtet dessen in nichtlinearer Weise voneinander abhängen. 
    Damit ist der Korrelationskoeffizient kein geeignetes Maß für die (reine) stochastische Abhängigkeit von Merkmalen.

    Der Pearson'sche Korrelationskoeffizient ist definiert durch
    \[
        \rho_{X,Y} := \frac{\Cov(X, Y)}{\sigma_X \cdot \sigma_Y}
    \]

    Von einer vorhandenen Korrelation zweier Zufallsvariablen darf aber nicht auf einen kausalen Zusammenhang gechlossen werden!
\end{defi}

\subsection{Gesetze der großen Zahlen und Grenzwertsätze}

\begin{defi}{Schwaches Gesetz großer Zahlen}
    Betrachte eine $n$-malige Wiederholung eines Zufallsexperimentes mit Messung der Zufallsvariablen (des Merkmals) $X$.
    Wir erhalten $n$ stochastisch unabhängige Ergebnisse. 
    
    $X_i$ sei die Realisierung der Zufallsvariablen im $i$-ten Versuch.

    $X_i$ ist dann eine Zufallsvariable mit der \emph{gleichen Verteilung} wie $X$, insbesondere aber auch mit \emph{gleichem Erwartungswert} und \emph{gleicher Varianz}.

    \[
        \conj{X}_{(n)} = \frac{1}{n} \sum_{i=1}^{n} X_i
    \] 

    ist dann auch eine Zufallsvariable mit 

    \[ 
        \implies \Mean(\conj{X}_{(n)}) = \frac{1}{n} \sum_{i=1}^{n} \Mean(X_i) = \frac{1}{n} \cdot n \cdot \Mean(X) = \Mean(X) 
    \] 
    und 
    \[ 
        \implies \Var(\conj{X}_{(n)}) = \frac{1}{n^2} \sum_{i=1}^{n} \Var(X_i) = \frac{1}{n^2} \cdot n \cdot \Var(X) = \frac{1}{n} \Var(X)
    \]

    Nach Tschebyscheff gilt dann: 
    \[
        P(\abs{\conj{X}_{(n)} - \mu} \geq \epsilon) \leq \frac{\Var(\conj{X}_{(n)})}{\epsilon^2} = \frac{\Var(X)}{n} \cdot \frac{1}{\epsilon} = \frac{1}{n} \cdot \frac{\sigma^2}{\epsilon^2}
    \]

    Mit 
    \[
        \lim_{n\to\infty} \frac{1}{n} \cdot \frac{\sigma^2}{\epsilon^2} = 0 \quad \text{und} \quad \conj{X}_{(n)} = \frac{1}{n}\sum_{i-1}^{n} X_i
    \]
    erhalten wir dann das \emph{Schwache Gesetz großer Zahlen}
    \[
        \lim_{n\to\infty} P \left( \abs{\frac{1}{n} \sum_{i=1}^n X_i - \mu} \geq \epsilon \right) = 0
    \]

    Dieses besagt \enquote{stochastische Konvergenz}: 
    Die Wahrscheinlichkeit, dass ein Mittelwert um mehr als ein beliebiges, festes $\epsilon > 0$ von $\mu$ abweicht, geht für wachsendes $n$ gegen Null.

    Es wird aber nicht ausgeschlossen, dass auch für unbeschränkt wachsende $n$ gelegentlich noch größere Abweichungen als $\epsilon$ auftreten.
    Die Wahrscheinlichkeit für solche \enquote{Ausreißer} geht mit wachsendem $n$ aber gegen Null.
\end{defi}

\begin{defi}{Starkes Gesetz großer Zahlen}
    Bei gleichen Voraussetzungen wie in der Herleitung für das schwache Gesetz großer Zahlen gilt auch das \emph{Starke Gesetz großer Zahlen}: 
    \[ 
        P \left( \lim_{n\to\infty} \abs{\frac{1}{n} \sum_{i-1}^n X_i - \mu} = 0 \right) = 1
    \] 

    Bei unbeschränkt oftmaliger Wiederholung der Messung einer Zufallsgröße konvergiert das Stichprobenmittel gegen den Erwartungswert von $X$.

    Das Starke Gesetz großer Zahlen kann ebenfalls \enquote{Ausreißer} nicht mit Sicherheit ausschließen.
\end{defi}

\begin{defi}{Zentraler Grenzwertsatz}
    Die unabhängigen Zufallsgrößen $X_1$, $X_2$, $\ldots$ sollen die gleiche Verteilung haben mit 
    \[
        \Mean(X_1) = \Mean(X_2) = \ldots = \mu    
        \quad \text{und} \quad 
        \Var(X_1) = \Var(X_2) = \ldots = \sigma^2
    \]

    Betrachte die Summe 
    \[ 
        S_n := \sum_{i=1}^n X_i
    \] 

    Dann gilt offensichtlich 
    \[ 
        \Mean(S_n) = \sum_{i=1}^n \Mean(X_i) = n \cdot \mu
        \quad \text{und} \quad 
        \Var(S_n) = \sum_{i=1}^n \Var(X_i) = n \cdot \sigma^2
    \] 

    Betrachte nun die \enquote{standardisierte Version} von $S_n$ als neue Zufallsgröße:
    \[
        S_n^* = \frac{S_n - \Mean(S_n)}{\sqrt{\Var(S_n)}} = \frac{\sum_{i=1}^n X_i - n \cdot \mu}{\sqrt{n} \cdot \sigma} = \frac{1}{\sqrt{n}} \cdot \sum_{i=1}^n \frac{X_i - \mu}{\sigma}
    \]

    Dann gilt der \emph{Zentrale Grenzwertsatz} nach Lindeberg und Lévy, welcher besagt:

    Für die Standardisierung 
    \[ 
        S_n^* = \frac{S_n - \Mean(S_n)}{\sqrt{\Var(S_n)}} 
    \] 
    der Summe 
    \[ 
        S_n = \sum_{i=1}^n X_i
    \] 
    gilt die Grenzwertbeziehung 
    \[ 
        \lim_{n\to\infty} P(S_n^* \leq s) = \frac{1}{\sqrt{2\pi}} \cdot \int_{-\infty}^s e^{\frac{x^2}{2}} \diff x \qquad \forall s \in \R
    \] 

    Der zentrale Grenzwertsatz liefert also die Begründung für das Phänomen, dass sich bei der additiven Überlagerung vieler kleiner unabhängiger Zufallseffekte zu einem Gesamteffekt zumindest approximativ eine Normalverteilung ergibt.
\end{defi}